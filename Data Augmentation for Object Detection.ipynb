{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KAMWysNPzP1V",
        "outputId": "9f7f6d10-6377-4ece-d64c-1eb95be915f0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qgz8UD2DzUK7"
      },
      "outputs": [],
      "source": [
        "from PIL import Image, ImageDraw\n",
        "import PIL\n",
        "import torch\n",
        "import os\n",
        "import torchvision.transforms.functional as F\n",
        "import numpy as np\n",
        "import random\n",
        "from IPython.display import display\n",
        "import os\n",
        "import cv2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NuU-KLH0z7_c"
      },
      "source": [
        "# Read Yolo Labels from .txt file:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CT7yE5Xlznpn"
      },
      "outputs": [],
      "source": [
        "def parse_yolo_label(label_str):\n",
        "  class_label, x_center, y_center, width, height = map(float, label_str.split())\n",
        "  bbox= [ x_center, y_center, width, height]\n",
        "  return [int(class_label)  ,bbox]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W_kH-HNI0CT0"
      },
      "source": [
        "# Convert normalized Yolo bounding box coordinates to pixel coordinates.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tUHiNNcHzqr-"
      },
      "outputs": [],
      "source": [
        "def xywhn2xyxy(x, w=640, h=640, padw=0, padh=0):\n",
        "    \"\"\"\n",
        "    Convert normalized bounding box coordinates to pixel coordinates.\n",
        "\n",
        "    Args:\n",
        "        x (np.ndarray | torch.Tensor): The bounding box coordinates.\n",
        "        w (int): Width of the image. Defaults to 640\n",
        "        h (int): Height of the image. Defaults to 640\n",
        "        padw (int): Padding width. Defaults to 0\n",
        "        padh (int): Padding height. Defaults to 0\n",
        "    Returns:\n",
        "        y (np.ndarray | torch.Tensor): The coordinates of the bounding box in the format [x1, y1, x2, y2] where\n",
        "            x1,y1 is the top-left corner, x2,y2 is the bottom-right corner of the bounding box.\n",
        "    \"\"\"\n",
        "    assert x.shape[-1] == 4, f\"input shape last dimension expected 4 but input shape is {x.shape}\"\n",
        "    y = torch.empty_like(x) if isinstance(x, torch.Tensor) else np.empty_like(x)\n",
        "    y[..., 0] = w * (x[..., 0] - x[..., 2] / 2) + padw  # top left x\n",
        "    y[..., 1] = h * (x[..., 1] - x[..., 3] / 2) + padh  # top left y\n",
        "    y[..., 2] = w * (x[..., 0] + x[..., 2] / 2) + padw  # bottom right x\n",
        "    y[..., 3] = h * (x[..., 1] + x[..., 3] / 2) + padh  # bottom right y\n",
        "    return y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qz3TvL2K0cYM"
      },
      "source": [
        "# Convert pixel coordinates to normalized Yolo bounding box coordinates:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qUAqspGq0Bwh"
      },
      "outputs": [],
      "source": [
        "def xyxy2xywhn(x, w=640, h=640, clip=False, eps=0.0):\n",
        "    \"\"\"\n",
        "    Convert bounding box coordinates from (x1, y1, x2, y2) format to (x, y, width, height, normalized) format. x, y,\n",
        "    width and height are normalized to image dimensions.\n",
        "\n",
        "    Args:\n",
        "        x (np.ndarray | torch.Tensor): The input bounding box coordinates in (x1, y1, x2, y2) format.\n",
        "        w (int): The width of the image. Defaults to 640\n",
        "        h (int): The height of the image. Defaults to 640\n",
        "        clip (bool): If True, the boxes will be clipped to the image boundaries. Defaults to False\n",
        "        eps (float): The minimum value of the box's width and height. Defaults to 0.0\n",
        "\n",
        "    Returns:\n",
        "        y (np.ndarray | torch.Tensor): The bounding box coordinates in (x, y, width, height, normalized) format\n",
        "    \"\"\"\n",
        "    if clip:\n",
        "        x = clip_boxes(x, (h - eps, w - eps))\n",
        "    assert x.shape[-1] == 4, f\"input shape last dimension expected 4 but input shape is {x.shape}\"\n",
        "    y = torch.empty_like(x) if isinstance(x, torch.Tensor) else np.empty_like(x)\n",
        "    y[..., 0] = ((x[..., 0] + x[..., 2]) / 2) / w  # x center\n",
        "    y[..., 1] = ((x[..., 1] + x[..., 3]) / 2) / h  # y center\n",
        "    y[..., 2] = (x[..., 2] - x[..., 0]) / w  # width\n",
        "    y[..., 3] = (x[..., 3] - x[..., 1]) / h  # height\n",
        "    return y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hiCgpKFV0rEk"
      },
      "source": [
        "# Doing Horizontal Flip:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "My-BK7id0bRv"
      },
      "outputs": [],
      "source": [
        "def horizontal_flip(image, boxes):\n",
        "    '''\n",
        "        Flip image horizontally.\n",
        "        image: a PIL image\n",
        "        boxes: Bounding boxes, a tensor of dimensions (#objects, 4)\n",
        "    '''\n",
        "    new_image = F.hflip(image)\n",
        "\n",
        "    #flip boxes\n",
        "    new_boxes = boxes.clone()\n",
        "    new_boxes[:, 0] = image.width - boxes[:, 0]\n",
        "    new_boxes[:, 2] = image.width - boxes[:, 2]\n",
        "    new_boxes = new_boxes[:, [2, 1, 0, 3]]\n",
        "    return new_image, new_boxes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7qFh7vj40wCr"
      },
      "source": [
        "# Doing Vertical Flip:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bst29zZE0y5s"
      },
      "outputs": [],
      "source": [
        "def vertical_flip(image, boxes):\n",
        "    '''\n",
        "        Flip image vertically.\n",
        "        image: a PIL image\n",
        "        boxes: Bounding boxes, a tensor of dimensions (#objects, 4)\n",
        "    '''\n",
        "    new_image = F.vflip(image)\n",
        "\n",
        "    # Flip boxes\n",
        "    new_boxes = boxes.clone()\n",
        "    new_boxes[:, 1] = image.height - boxes[:, 1]\n",
        "    new_boxes[:, 3] = image.height - boxes[:, 3]\n",
        "    new_boxes = new_boxes[:, [0, 3, 2, 1]]\n",
        "    return new_image, new_boxes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "81im1nvF09ja"
      },
      "source": [
        "# Doing Rotation:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7eNRcNSX07et"
      },
      "outputs": [],
      "source": [
        "def rotate(image, boxes, angle,width_image,height_image):\n",
        "    '''\n",
        "        Rotate image and bounding box\n",
        "        image: A Pil image (w, h)\n",
        "        boxes: A tensors of dimensions (#objects, 4)\n",
        "\n",
        "        Out: rotated image (w, h), rotated boxes\n",
        "    '''\n",
        "    new_image = image.copy()\n",
        "    new_boxes = boxes.clone()\n",
        "\n",
        "    w = image.width\n",
        "    h = image.height\n",
        "    cx = w/2\n",
        "    cy = h/2\n",
        "    new_image = new_image.rotate(angle, expand= True)\n",
        "    angle = np.radians(angle)\n",
        "    alpha = np.cos(angle)\n",
        "    beta = np.sin(angle)\n",
        "    #Get affine matrix\n",
        "    AffineMatrix = torch.tensor([[alpha, beta, (1-alpha)*cx - beta*cy],\n",
        "                                 [-beta, alpha, beta*cx + (1-alpha)*cy]])\n",
        "\n",
        "    #Rotation boxes\n",
        "    box_width = (boxes[:,2] - boxes[:,0]).reshape(-1,1)\n",
        "    box_height = (boxes[:,3] - boxes[:,1]).reshape(-1,1)\n",
        "\n",
        "    #Get corners for boxes\n",
        "    x1 = boxes[:,0].reshape(-1,1)\n",
        "    y1 = boxes[:,1].reshape(-1,1)\n",
        "\n",
        "    x2 = x1 + box_width\n",
        "    y2 = y1\n",
        "\n",
        "    x3 = x1\n",
        "    y3 = y1 + box_height\n",
        "\n",
        "    x4 = boxes[:,2].reshape(-1,1)\n",
        "    y4 = boxes[:,3].reshape(-1,1)\n",
        "\n",
        "    corners = torch.stack((x1,y1,x2,y2,x3,y3,x4,y4), dim= 1)\n",
        "    corners = corners.reshape(-1,2)\n",
        "    corners = torch.cat((corners, torch.ones(corners.shape[0], 1)), dim= 1)\n",
        "\n",
        "    cos = np.abs(AffineMatrix[0, 0])\n",
        "    sin = np.abs(AffineMatrix[0, 1])\n",
        "\n",
        "    nW = int((h * sin) + (w * cos))\n",
        "    nH = int((h * cos) + (w * sin))\n",
        "    AffineMatrix[0, 2] += (nW / 2) - cx\n",
        "    AffineMatrix[1, 2] += (nH / 2) - cy\n",
        "\n",
        "    #Apply affine transform\n",
        "    AffineMatrix = AffineMatrix.float()  #\n",
        "    rotate_corners = torch.mm(AffineMatrix, corners.t()).t()\n",
        "    rotate_corners = rotate_corners.reshape(-1,8)\n",
        "\n",
        "    x_corners = rotate_corners[:,[0,2,4,6]]\n",
        "    y_corners = rotate_corners[:,[1,3,5,7]]\n",
        "\n",
        "    #Get (x_min, y_min, x_max, y_max)\n",
        "    x_min, _ = torch.min(x_corners, dim= 1)\n",
        "    x_min = x_min.reshape(-1, 1)\n",
        "    y_min, _ = torch.min(y_corners, dim= 1)\n",
        "    y_min = y_min.reshape(-1, 1)\n",
        "    x_max, _ = torch.max(x_corners, dim= 1)\n",
        "    x_max = x_max.reshape(-1, 1)\n",
        "    y_max, _ = torch.max(y_corners, dim= 1)\n",
        "    y_max = y_max.reshape(-1, 1)\n",
        "\n",
        "    new_boxes = torch.cat((x_min, y_min, x_max, y_max), dim= 1)\n",
        "\n",
        "    scale_x = new_image.width / w\n",
        "    scale_y = new_image.height / h\n",
        "\n",
        "    #Resize new image to (w, h)\n",
        "    new_image = new_image.resize((width_image, height_image))\n",
        "\n",
        "    #Resize boxes\n",
        "    new_boxes /= torch.Tensor([scale_x, scale_y, scale_x, scale_y])\n",
        "    new_boxes[:, 0] = torch.clamp(new_boxes[:, 0], 0, w)\n",
        "    new_boxes[:, 1] = torch.clamp(new_boxes[:, 1], 0, h)\n",
        "    new_boxes[:, 2] = torch.clamp(new_boxes[:, 2], 0, w)\n",
        "    new_boxes[:, 3] = torch.clamp(new_boxes[:, 3], 0, h)\n",
        "    return new_image, new_boxes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p9VRXM6f1H_S"
      },
      "source": [
        "# Start The Augmentaion Process:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GxKclgQP1O2z"
      },
      "source": [
        "# ================================================================================"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zq-pArRB1ZEJ"
      },
      "source": [
        "## Horizontal Flip Part:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7ruSsgny1FLz"
      },
      "outputs": [],
      "source": [
        "def augment_data(image_path, label_path, save_dir):\n",
        "  # Read image and label\n",
        "  image = Image.open(image_path, mode= \"r\")\n",
        "  image = image.convert(\"RGB\")\n",
        "  width, height = image.size\n",
        "  with open(label_path, 'r') as f:\n",
        "    labels = [parse_yolo_label(line.strip()) for line in f.readlines()]\n",
        "  bbox = [label[1] for label in labels]\n",
        "  class_label = [label[0] for label in labels]\n",
        "  flat_list = [item for sublist in bbox for item in sublist]\n",
        "  xy_list = flat_list\n",
        "  xy_tensor = torch.tensor(xy_list).reshape(-1, 4)\n",
        "  xy_coords = xywhn2xyxy(xy_tensor, width, height)\n",
        "\n",
        "\n",
        "  boxes = torch.FloatTensor(xy_coords)\n",
        "  torch.set_printoptions(sci_mode=False, precision=15)\n",
        "\n",
        "  # Apply Horizontal Flip for image and boxes\n",
        "  image_Hflip, new_boxes = horizontal_flip(image, boxes)\n",
        "\n",
        "\n",
        "  yolo_list = new_boxes\n",
        "  yolo_tensor = torch.tensor(yolo_list)\n",
        "  yolo_coords = xyxy2xywhn(yolo_tensor, width, height)\n",
        "\n",
        "\n",
        "  coords_list = yolo_coords.tolist()\n",
        "\n",
        "  i=0\n",
        "   # Generate unique filenames\n",
        "  filename, ext = os.path.splitext(os.path.basename(image_path))\n",
        "  new_filename = f\"{filename}_aug_{i+1}HF{ext}\"\n",
        "  save_path = os.path.join(save_dir, new_filename)\n",
        "  image_Hflip.save(save_path)\n",
        "\n",
        "  with open(os.path.join(save_dir, f\"{new_filename[:-len(ext)]}.txt\"), 'w') as f:\n",
        "        for label, coord in zip(class_label, coords_list):\n",
        "            # Write augmented class ID\n",
        "            f.write(f\"{label} \")\n",
        "\n",
        "            # Write bounding box coordinates from augmented_labels\n",
        "            f.write(' '.join(map(str, coord)) + '\\n')\n",
        "\n",
        "  print(\"Image \", new_filename , \"Done Successfuly\")\n",
        "  print(\"======================================================================\")\n",
        "\n",
        "\n",
        "\n",
        "# Modify these paths according to your dataset\n",
        "image_dir = \"\"\n",
        "label_dir = \"\"\n",
        "save_dir = \"\"\n",
        "\n",
        "\n",
        "count = 0\n",
        "# Loop through images and labels\n",
        "for image_filename in os.listdir(image_dir):\n",
        "  image_path = os.path.join(image_dir, image_filename)\n",
        "  label_path = os.path.join(label_dir, os.path.splitext(image_filename)[0] + \".txt\")\n",
        "  augment_data(image_path, label_path, save_dir)\n",
        "  count += 1\n",
        "\n",
        "print(\"Number of Images Done: \", count)\n",
        "print(\"Data augmentation completed!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bxPDPo962GuU"
      },
      "source": [
        "## Vertical Flip Part:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IAAAgHe52JZb"
      },
      "outputs": [],
      "source": [
        "def augment_data(image_path, label_path, save_dir):\n",
        "  image = Image.open(image_path, mode= \"r\")\n",
        "  image = image.convert(\"RGB\")\n",
        "  width, height = image.size\n",
        "  with open(label_path, 'r') as f:\n",
        "    labels = [parse_yolo_label(line.strip()) for line in f.readlines()]\n",
        "\n",
        "  bbox = [label[1] for label in labels]\n",
        "  class_label = [label[0] for label in labels]\n",
        "\n",
        "  flat_list = [item for sublist in bbox for item in sublist]\n",
        "  xy_list = flat_list\n",
        "  xy_tensor = torch.tensor(xy_list).reshape(-1, 4)\n",
        "  xy_coords = xywhn2xyxy(xy_tensor, width, height)\n",
        "\n",
        "\n",
        "  boxes = torch.FloatTensor(xy_coords)\n",
        "  torch.set_printoptions(sci_mode=False, precision=15)\n",
        "\n",
        "  # Apply Vertical Flip for image and boxes\n",
        "  image_Vflip, new_boxes = vertical_flip(image, boxes)\n",
        "\n",
        "  yolo_list = new_boxes\n",
        "  yolo_tensor = torch.tensor(yolo_list)\n",
        "  yolo_coords = xyxy2xywhn(yolo_tensor, width, height)\n",
        "\n",
        "\n",
        "  coords_list = yolo_coords.tolist()\n",
        "\n",
        "  i=0\n",
        "   # Generate unique filenames\n",
        "  filename, ext = os.path.splitext(os.path.basename(image_path))\n",
        "  new_filename = f\"{filename}_aug_{i+1}VF{ext}\"\n",
        "  save_path = os.path.join(save_dir, new_filename)\n",
        "  image_Vflip.save(save_path)\n",
        "\n",
        "  with open(os.path.join(save_dir, f\"{new_filename[:-len(ext)]}.txt\"), 'w') as f:\n",
        "        for label, coord in zip(class_label, coords_list):\n",
        "            # Write augmented class ID\n",
        "            f.write(f\"{label} \")\n",
        "\n",
        "            # Write bounding box coordinates from augmented_labels\n",
        "            f.write(' '.join(map(str, coord)) + '\\n')\n",
        "\n",
        "  print(\"Image \", new_filename , \"Done Successfuly\")\n",
        "  print(\"======================================================================\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Modify these paths according to your dataset\n",
        "image_dir = \"\"\n",
        "label_dir = \"\"\n",
        "save_dir = \"\"\n",
        "\n",
        "\n",
        "count = 0\n",
        "# Loop through images and labels\n",
        "for image_filename in os.listdir(image_dir):\n",
        "  image_path = os.path.join(image_dir, image_filename)\n",
        "  label_path = os.path.join(label_dir, os.path.splitext(image_filename)[0] + \".txt\")\n",
        "  augment_data(image_path, label_path, save_dir)\n",
        "  count += 1\n",
        "  print(count)\n",
        "\n",
        "print(\"Number of Images Done: \", count)\n",
        "print(\"Data augmentation completed!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4PEyazIw2QXI"
      },
      "source": [
        "## Rotation by 90 degree Part:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ABXSYhqK2VLT"
      },
      "outputs": [],
      "source": [
        "def augment_data(image_path, label_path, save_dir):\n",
        "  image = Image.open(image_path, mode= \"r\")\n",
        "  image = image.convert(\"RGB\")\n",
        "  width, height = image.size\n",
        "  with open(label_path, 'r') as f:\n",
        "    labels = [parse_yolo_label(line.strip()) for line in f.readlines()]\n",
        "\n",
        "  bbox = [label[1] for label in labels]\n",
        "  class_label = [label[0] for label in labels]\n",
        "\n",
        "  flat_list = [item for sublist in bbox for item in sublist]\n",
        "  xy_list = flat_list\n",
        "  xy_tensor = torch.tensor(xy_list).reshape(-1, 4)\n",
        "  xy_coords = xywhn2xyxy(xy_tensor, width, height)\n",
        "\n",
        "\n",
        "  boxes = torch.FloatTensor(xy_coords)\n",
        "  torch.set_printoptions(sci_mode=False, precision=15)\n",
        "\n",
        "  # Apply Rotation by 90 for image and boxes\n",
        "  image_rotate, new_boxes = rotate(image, boxes,90,width,height)\n",
        "\n",
        "\n",
        "  yolo_list = new_boxes\n",
        "  yolo_tensor = torch.tensor(yolo_list)\n",
        "  yolo_coords = xyxy2xywhn(yolo_tensor, width, height)\n",
        "\n",
        "\n",
        "  coords_list = yolo_coords.tolist()\n",
        "\n",
        "  i=0\n",
        "   # Generate unique filenames\n",
        "  filename, ext = os.path.splitext(os.path.basename(image_path))\n",
        "  new_filename = f\"{filename}_aug_{i+1}R90{ext}\"\n",
        "  save_path = os.path.join(save_dir, new_filename)\n",
        "  image_rotate.save(save_path)\n",
        "\n",
        "  with open(os.path.join(save_dir, f\"{new_filename[:-len(ext)]}.txt\"), 'w') as f:\n",
        "        for label, coord in zip(class_label, coords_list):\n",
        "            # Write augmented class ID\n",
        "            f.write(f\"{label} \")\n",
        "\n",
        "            # Write bounding box coordinates from augmented_labels\n",
        "            f.write(' '.join(map(str, coord)) + '\\n')\n",
        "\n",
        "  print(\"Image \", new_filename , \"Done Successfuly\")\n",
        "  print(\"======================================================================\")\n",
        "\n",
        "\n",
        "\n",
        "# Modify these paths according to your dataset\n",
        "image_dir = \"\"\n",
        "label_dir = \"\"\n",
        "save_dir = \"\"\n",
        "\n",
        "\n",
        "count = 0\n",
        "# Loop through images and labels\n",
        "for image_filename in os.listdir(image_dir):\n",
        "  image_path = os.path.join(image_dir, image_filename)\n",
        "  label_path = os.path.join(label_dir, os.path.splitext(image_filename)[0] + \".txt\")\n",
        "  augment_data(image_path, label_path, save_dir)\n",
        "  count += 1\n",
        "  print(count)\n",
        "\n",
        "print(\"Number of Images Done: \", count)\n",
        "print(\"Data augmentation completed!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Rotation by 270 degree part:"
      ],
      "metadata": {
        "id": "kwIrx__DtxGR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def augment_data(image_path, label_path, save_dir):\n",
        "  image = Image.open(image_path, mode= \"r\")\n",
        "  image = image.convert(\"RGB\")\n",
        "  width, height = image.size\n",
        "  with open(label_path, 'r') as f:\n",
        "    labels = [parse_yolo_label(line.strip()) for line in f.readlines()]\n",
        "\n",
        "  bbox = [label[1] for label in labels]\n",
        "  class_label = [label[0] for label in labels]\n",
        "\n",
        "  flat_list = [item for sublist in bbox for item in sublist]\n",
        "  xy_list = flat_list\n",
        "  xy_tensor = torch.tensor(xy_list).reshape(-1, 4)\n",
        "  xy_coords = xywhn2xyxy(xy_tensor, width, height)\n",
        "\n",
        "\n",
        "  boxes = torch.FloatTensor(xy_coords)\n",
        "  torch.set_printoptions(sci_mode=False, precision=15)\n",
        "\n",
        " # Apply Rotation by 270 for image and boxes\n",
        "  image_rotate, new_boxes = rotate(image, boxes,270,width,height)\n",
        "\n",
        "\n",
        "\n",
        "  yolo_list = new_boxes\n",
        "  yolo_tensor = torch.tensor(yolo_list)\n",
        "  yolo_coords = xyxy2xywhn(yolo_tensor, width, height)\n",
        "\n",
        "\n",
        "  coords_list = yolo_coords.tolist()\n",
        "\n",
        "  i=0\n",
        "   # Generate unique filenames\n",
        "  filename, ext = os.path.splitext(os.path.basename(image_path))\n",
        "  new_filename = f\"{filename}_aug_{i+1}R270{ext}\"\n",
        "  save_path = os.path.join(save_dir, new_filename)\n",
        "  image_rotate.save(save_path)\n",
        "\n",
        "  with open(os.path.join(save_dir, f\"{new_filename[:-len(ext)]}.txt\"), 'w') as f:\n",
        "        for label, coord in zip(class_label, coords_list):\n",
        "            # Write augmented class ID\n",
        "            f.write(f\"{label} \")\n",
        "\n",
        "            # Write bounding box coordinates from augmented_labels\n",
        "            f.write(' '.join(map(str, coord)) + '\\n')\n",
        "\n",
        "  print(\"Image \", new_filename , \"Done Successfuly\")\n",
        "  print(\"======================================================================\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Modify these paths according to your dataset\n",
        "image_dir = \"\"\n",
        "label_dir = \"\"\n",
        "save_dir = \"\"\n",
        "\n",
        "\n",
        "count = 0\n",
        "# Loop through images and labels\n",
        "for image_filename in os.listdir(image_dir):\n",
        "  image_path = os.path.join(image_dir, image_filename)\n",
        "  label_path = os.path.join(label_dir, os.path.splitext(image_filename)[0] + \".txt\")\n",
        "  augment_data(image_path, label_path, save_dir)\n",
        "  count += 1\n",
        "  print(count)\n",
        "\n",
        "print(\"Number of Images Done: \", count)\n",
        "print(\"Data augmentation completed!\")"
      ],
      "metadata": {
        "id": "fJDfVOLst0KB"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}